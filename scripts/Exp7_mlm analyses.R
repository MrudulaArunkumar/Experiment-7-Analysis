#workspace aufraeumen####
rm(list=ls())

#notwendige Pakete laden####
library(plyr)
library(lme4)
library(tidyverse)
library(here)


#set working directory
#set_here()
setwd("~/Daten/1 BRAC-FOR/overshadowing/Exp 7/Analysis")


Exp7data <- read.csv(file="Data/Exp7_fulldataset.csv")

Exp7data$participant <- as.factor(Exp7data$participant)



# Data preparation and cleaning

# -   Removing unnecessary columns generated by psychopy
# -   Preparing the RT trial, by eliminating the square brackets and splitting it in cases where two keys were registered.
# -   Creating a column for Accuracy and Error Rate
# -   adding a Bonus column that computes the points received by each participant

Exp7data <- Exp7data %>%
  select(-X,-ConsentKey.keys,-ConsentKey.rt,-Begin.keys,-Begin.rt,-checkresp.corr,-checkresp.keys,-checkresp.rt,-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisN,-Attention.thisIndex,-Attention.ran,-AttnQuestion,-AttnAnswer,-NextStep.keys,-NextStep.rt,-InstRep.ran,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,-InstRep.thisIndex,-PracProceed.keys,-PracProceed.rt,-Prac_loop.thisRepN,-Prac_loop.thisTrialN,-Prac_loop.thisN,-Prac_loop.thisIndex,-Prac_loop.ran,-Exp_proceed.keys,-Exp_proceed.rt,-PracRepeat.ran,-PracRepeat.thisRepN,-PracRepeat.thisN,-PracRepeat.thisIndex,-PracRepeat.thisTrialN,-brkContinue.keys,-PauseResp.keys,-PauseResp.rt,-CALearntrials.thisRepN,-CALearntrials.ran,-CALearntrials.thisTrialN,-CALearntrials.thisIndex, -CA_Proceed.keys,-CA_Proceed.rt,-headstartLearn.thisRepN,-headstartLearn.thisTrialN,-headstartLearn.thisIndex,-headstartLearn.thisN,-headstartLearn.ran,-ExpTrials.ran,-ExpTrials.thisIndex,-CA_trials.thisRepN,-CA_trials.thisN,-CA_trials.thisIndex,-CA_trials.thisTrialN,-CA_trials.ran,-AwareQ_loop.thisRepN,-AwareQ_loop.ran,-AwareQ_loop.thisIndex,-AwareQ_loop.thisTrialN,-todebrief.keys,-Finalend.keys)



#adjusting RT
Exp7data$mainRT <- Exp7data$TargetResp.rt
Exp7data$Block1RT <- Exp7data$CAResponse.rt

#splitting the RTs from main block
Exp7data <- separate(Exp7data, col = mainRT, into = c("RTm_Trials", "RTm_secondary"), sep = ',')
Exp7data$RTm_Trials <- Exp7data$RTm_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp7data$RTm_Trials)
Exp7data$RTm_Trials <- 1000*(Exp7data$RTm_Trials)

#splitting RTs from the Ca learn block (1st block)
Exp7data <- separate(Exp7data, col = Block1RT, into = c("RTb_Trials", "RTb_secondary"), sep = ',')
Exp7data$RTb_Trials <- Exp7data$RTb_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp7data$RTb_Trials)
Exp7data$RTb_Trials <- 1000*(Exp7data$RTb_Trials)

#removing RTs from guessing trials 
Exp7data$RTb_Trials <- ifelse(Exp7data$Block == "CG Learn", NA, Exp7data$RTb_Trials)

#creating a dummy variable to pick wherever the RTs are from main block and which are from first block
Exp7data$RTdummy <- ifelse(is.na(Exp7data$TargetResp.rt) == FALSE,1,NA)
Exp7data$RTdummy <- ifelse(is.na(Exp7data$CAResponse.rt)==FALSE,2,Exp7data$RTdummy)

#combining all important RTs 
Exp7data <- Exp7data %>%
  mutate(RT_Trials = ifelse((RTdummy == 1), RTm_Trials,ifelse((RTdummy == 2),RTb_Trials,NA)))


###creating a separate df with the contingency awareness
Exp7_CA <- Exp7data%>%
  filter(Target == "?" | str_detect(AwareQ, "Press"))





Exp7data <- Exp7data%>%drop_na(RT_Trials)

#combining accuracy from first block and main block
Exp7data$mainAcc <- Exp7data$TargetResp.corr
Exp7data$Block1Acc <- Exp7data$CAResponse.corr
Exp7data$BlockAcc <- ifelse(Exp7data$Block == "CG Learn", NA, Exp7data$Block1Acc)

Exp7data$ACCdummy <- ifelse(is.na(Exp7data$TargetResp.corr)==FALSE,1,NA)
Exp7data$ACCdummy <- ifelse(is.na(Exp7data$CAResponse.corr)==FALSE,2,Exp7data$ACCdummy)

Exp7data <- Exp7data %>%
  mutate(ACC_trials = ifelse((ACCdummy == 1),mainAcc,ifelse((ACCdummy == 2),Block1Acc,NA)))


Exp7data$ErrorRate <- 1 - Exp7data$ACC_trials

#Error rate
table(Exp7data$ACC_trials)
round(table(Exp7data$ACC_trials)/nrow(Exp7data)*100, digits = 3)

#Exclude errors from RT

Exp7data$RT_Trials[Exp7data$ACC_trials==0] <- NA
summary(Exp7data$RT_Trials)

#exclude outliers
#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp7data <- ddply(Exp7data, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp7data$RT_io <- Exp7data$RT_Trials

Exp7data$RT_io[Exp7data$RT_io > Exp7data$Outlier|Exp7data$RT_io < 200] <- NA
summary(Exp7data$RT_io)

#+++++++++++++++++++++++++++++++++++####
#MULTILEVEL ANALYSIS####
#+++++++++++++++++++++++++++++++++++++++

#Compute first model: level1 predictor: probe compatiblity; level2 predictor: subject;
#random slopes, predict RT with contingency factor (high vs low) = aka "probe_comp" var ####

raw.data<-Exp7data

#compute new numeric var for validity effect
raw.data$val <-ifelse(raw.data$Validity=="valid",1,2)
table(raw.data$val, raw.data$Validity)


randomSlopes_m1<-lmer(RT_io~1+val + (1+val|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m1)



#add previous_respoonse and distance to the model####
Exp7data <- Exp7data%>%select(Condition, SalD,NSalD,Saliency,Validity, everything())

###first is to find out the trials where the previous occurence wa the immediate previous one
Exp7data$Distance <- NA
Exp7data <- Exp7data%>%select(Distance,ACC_trials,everything())
Exp7data <- Exp7data%>%
  mutate(Distance = ifelse((lag(Condition,1)=="test" | lag(Condition,1) == "learn")& 
                             (lag(SalD,1)== SalD|lag(NSalD,1)==NSalD) &
                             lag(participant,1)==participant &
                             lag(ACC_trials,1)== 1, 1, Distance))


#The number of immediate previous occurences

table(Exp7data$Distance)

## Now to look at other distances of the last occurrence beyond the immediately preceding one
lagvalue <- 2:20

for(j in lagvalue){
  Exp7data <- Exp7data %>% 
    mutate(Distance = ifelse((lag(Condition,j)=="learn"|lag(Condition,j)=="test") &  
                             (lag(SalD,j)==SalD|lag(NSalD,j)==NSalD) & lag(participant,j)==participant &
                              lag(ACC_trials,j)== 1 & is.na(Distance)==TRUE, j, Distance))
}

table(Exp7data$Distance)

### Previous Response

# Coding what the previous Response was, whether it was the same or different. This variable is defined as Response Type, which has two factors: Response Change(RC) and Response Repetition (RR)
# 
# *To be noted: This does not equate to validity* because the SRB trials can have the combination of invalid prime and invalid probe --> Response Repetition which is confounded by Validity. 
# So every valid probe can have both the Response Type factors based on whether the prime is valid or invalid
# 


Exp7data$ResponseType <- NA

Rmlag <- 1:30
for(k in Rmlag){
  Exp7data <- Exp7data %>% 
    mutate(ResponseType = ifelse((lag(Condition,k)=="learn" | lag(Condition,k)=="test") &  
                                   (lag(SalD,k)==SalD|lag(NSalD,k)==NSalD) & lag(participant,k)==participant & 
                                   lag(CorrectAnswer,k)== CorrectAnswer & is.na(ResponseType)==TRUE, "RR", 
                                 ifelse((lag(Condition,k)=="learn"|lag(Condition,k)=="test") & (lag(SalD,k)==SalD|lag(NSalD,k)==NSalD)& lag(participant,k)==participant & lag(CorrectAnswer,k)!= CorrectAnswer & is.na(ResponseType)==TRUE, "RC", ResponseType)))
}

table(Exp7data$ResponseType)

Exp7data <- Exp7data%>%select(ResponseType,RT_io,CorrectAnswer, everything())


raw.data <-Exp7data
raw.data<-subset(raw.data, subset=(raw.data$participant!="10"))

#compute new numeric var for validity effect
raw.data$val <-ifelse(raw.data$Validity=="valid",1,2)
table(raw.data$val, raw.data$Validity)
summary(raw.data$val)


#create numerical var for response type

raw.data$previous_rm<-ifelse(raw.data$ResponseType=="RR", 1, 2)
table(raw.data$ResponseType, raw.data$previous_rm)


#center predictors

raw.data$Zval=scale(raw.data$val, scale=FALSE)
raw.data$Zprevious_rm=scale(raw.data$previous_rm, scale=F)
raw.data$ZDistance=scale(raw.data$Distance, scale=F)

summary(raw.data$ZDistance)
summary(raw.data$Distance)

randomSlopes_m2<-lmer(RT_io~1+Zval + Zprevious_rm + ZDistance + (1+Zval +Zprevious_rm +ZDistance |participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m2)
table(raw.data$Block)
#run model without head start trials (40 valid only trials)
raw.data<-subset(raw.data, subset = (raw.data$Block!="HeadStart" & raw.data$Block!="SalMC"))





randomSlopes_m2<-lmer(RT_io~1+Zval + Zprevious_rm + ZDistance + (1+Zval +Zprevious_rm +ZDistance |participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")
summary(randomSlopes_m2)

#incorporate interaction between previous_rm and distance
randomSlopes_m3<-lmer(RT_io~1+Zval + Zprevious_rm*ZDistance + (1+Zval +Zprevious_rm*ZDistance |participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m3)
#Doublecheck meaning of distance*previous_rm interaction with Klaus: Due to bigger difference of RR vs RC fOr distance of 1 and distance of 2 (which fall below 0 when transformed to Z scores?) 
#compared to more distant distannces (there, the difference between RR and RC should be much smaller...)

randomIntercept_m0<-lmer(RT_io~1 + (1|participant), 
                         data=raw.data, 
                         REML=F,
                         na.action = "na.omit")
summary(randomIntercept_m0)


#Model comparison
#Model 3 vs Model0

anova(randomIntercept_m0, randomSlopes_m3)
#model 3 has sign better fit than model 0

anova(randomIntercept_m0, randomSlopes_m2)
#model 2 has sign better fit than model 0

####Run MLM only for salient D's (because only these show the validity effect) ###

table(raw.data$Condition, raw.data$Saliency)
raw.data<-subset(raw.data, subset=(raw.data$Condition=="test" & raw.data$Saliency=="Salient"))

randomSlopes_m4<-lmer(RT_io~1+val + (1+val|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m4)


randomSlopes_m5<-lmer(RT_io~1+Zval + Zprevious_rm + ZDistance + (1+Zval +Zprevious_rm +ZDistance |participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m5)

#incorporate interaction between previous_rm and distance
randomSlopes_m6<-lmer(RT_io~1+Zval + Zprevious_rm*ZDistance + (1+Zval +Zprevious_rm*ZDistance |participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m6)

#Compare models, m0 vs m4
anova(randomIntercept_m0, randomSlopes_m4)
#model 4 has sign better fit than model 0

anova(randomSlopes_m5, randomSlopes_m4)
#model 5 is not better than model 4
