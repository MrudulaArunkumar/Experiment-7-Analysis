---
title: "Binding level Analysis of Experiment 7"
author: "Carina"
date: "`r format(Sys.time(), '%d %B,%Y')`"
output:
  html_document:
    theme: readable
    highlight: breezedark
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 7
    fig_height: 4
    code_folding: hide
---


### Data Preparation ###

The full dataset is loaded and the unnecessary columns are removed and the RT and ACC columns are prepared. 
The exclusion criteria (Tukey cut offs for outliers and RTs less than 200ms) are computed and the outlier RTs are removed.
This prepared data is then saved as **data_prepared.csv** and used for further analysis.
Participant 10 is removed from the dataset due to high number of errors (~25%)



```{r}
library(plyr)
library(lme4)
library(lmerTest)
library(tidyverse)
library(ez)
library(ggplot2)
library(schoRsch)
library(here)
library(sjPlot)
library(knitr)
library(pander)
library(rmarkdown)

```


Creating a new column (*binding sequence*) that identifies all the binding trials

- These are trials where Trial $n$ is a *test* trial (probe) and Trial $n-1$ is a *learn* trial (prime).
- Only accurate primes are used




```{r}
#read prepared file (outliers and errors excluded)
raw.data<-read.csv2(file=here("Data","data_prepared.csv"))

#exclude participant with too many errors
raw.data<-subset(raw.data, subset=(raw.data$participant!="10"))

#reduce dataset
raw.data<-raw.data%>%
  select(Validity, Saliency, Condition, SalD, NSalD, CorrectAnswer, Target, RT_Trials, ACC_trials, participant, RT_io)

#limit dataset to sequences with trial n-1=learn and trial n=test####
raw.data<-raw.data%>%
  mutate(binding_sequence= ifelse(Condition=="test" & lag(Condition,1)=="learn" & lag(ACC_trials,1)==1 & lag(participant,1)==participant, 1,0))

raw.data<-raw.data%>%
  select(binding_sequence, Condition, everything())

pander(table(raw.data$binding_sequence), style = "rmarkdown", caption = "Number of binding, prime-probe sequences")
#3832 relevant sequences

```

### Introducing the factors used for analysis

1. **DRel (Distractor Relation)**: 

-This factor is computed for these binding sequences where probe is a test trial and if the saliency is salient/nonsalient and the Salient/NonSalient Distractor of prime is same as the probe then the factor is *Distractor Repetition (DR)*
- For these binding sequences where probe is a test trial and if the saliency is salient/nonsalient and the Salient/NonSalient Distractor of prime is different from the probe, then the factor is *Distractor Change (DC)*


```{r factors, warning=FALSE, message=FALSE}
#code factors####
#DRel
raw.data<-raw.data%>%
  mutate(DRel =ifelse(binding_sequence==1 & Condition=="test" & Saliency=="Salient" & lag(SalD,1) == SalD,"DR",
                      ifelse(binding_sequence==1 & Condition=="test" & Saliency=="NonSalient" & lag(NSalD,1) == NSalD,"DR",
                             ifelse(binding_sequence==1 & Condition=="test" & Saliency=="Salient" & lag(SalD,1) != SalD,"DC",
                                    ifelse(binding_sequence==1 & Condition=="test" & Saliency=="NonSalient" & lag(NSalD,1) != NSalD,"DC",NA))))
         )

pander(table(raw.data$DRel), style = "rmarkdown", caption = "Distractor Relations for all binding sequences")
```


2. **RRel (Response Relation)**: 

-This factor is computed for these binding sequences where probe is a test trial and if prime's correct response is same as the probe then the factor is *Response Repetition (RR)*
- For these binding sequences where probe is a test trial and if the prime's correct response is different from the probe's , then the factor is *Response Change (RC)*


```{r rrel, message=FALSE, warning=FALSE}
#RREl
raw.data<-raw.data%>%
  mutate(RRel=ifelse(binding_sequence==1 & CorrectAnswer==lag(CorrectAnswer,1), "RR",
                     ifelse(binding_sequence==1 & CorrectAnswer!=lag(CorrectAnswer,1), "RC",NA)))

pander(table(raw.data$RRel), style = "rmarkdown", caption = "Response Relation for all the binding sequences")
```

3. **Probe Saliency**

- This is the same as the Saliency Factor but recoded in the binding scenario by coding the test trial's saliency as probe saliency

```{r probesal, message=FALSE,warning=FALSE}
#Probesalience
#equate to Saliency
raw.data<-raw.data%>%
  mutate(ProbeSaliency=ifelse(binding_sequence==1 & Condition=="test" &Saliency == "Salient", "salient",
                              ifelse(binding_sequence==1 & Condition=="test" &Saliency == "NonSalient", "nonsalient", NA)))

pander(table(raw.data$ProbeSaliency), style = "rmarkdown", caption = "Salient and Non Salient probes")
```


Now, the dataframe is reduced to only the binding sequences trials 

```{r}
#get rid of all trials except test trials in relevant binding sequence
raw.data<-subset(raw.data, subset=(raw.data$binding_sequence==1))
raw.data$err<-1-raw.data$ACC_trials

pander(table(raw.data$Validity), style = "rmarkdown", caption = "Number of valid and invalid trials in the SRB trials")
```



### Creating aggregate files

The following aggregate files are created:

1. Aggregate with RTs against the above three factors across participant
2. Aggregate with ERs against the above three factors across participant

*While adding the validity factor in the aggregate command there are too many missing values which does not help with the ezANOVA function, hence it was not included in these aggregate files*

3. Only valid test trials are selected from the main df, and an aggregate is created using that data frame (**only valid**) with the above three factors across participant. MLM will be used in this case to circumbent the multiple missing values

```{r}
agg.out <- aggregate(data = raw.data, RT_io ~ DRel + RRel + ProbeSaliency  + participant,mean)
agg.err <- aggregate(data = raw.data, err ~ DRel + RRel + ProbeSaliency  + participant, mean)


#
#limit analyses only to valid test trials to avoid problem of too many missings
raw.data<-subset(raw.data, subset=(raw.data$Validity=="valid"))
OnlyVal_agg.out<- aggregate(data = raw.data, RT_io ~ DRel + RRel + ProbeSaliency  + participant, mean)
#too many empty cells to carry out ANOVA -> Model at the trial level to circumvent problem of missing data

#write.csv2(OnlyVal_agg.out, file="Data/val_agg_out.csv", row.names = F)

```


## 1. ANOVA: DRel, RRel, Probe saliency for binding trials with RTs

> The three way interaction is significant, $F = 8.10, p = 0.005$

```{r}
anova1 <- ezANOVA(data = agg.out,
                  dv = RT_io,
                  wid = .(participant),
                  within = .(DRel,RRel,ProbeSaliency),
                  detailed = TRUE)

pander(anova1, style = "rmarkdown", caption = "ANOVA (RT): for binding trials with DRel, RRel, ProbeSaliency")

plotDRRR <- ggplot(data = agg.out,aes(x = RRel, y = RT_io, color = DRel))+
  geom_line(aes(group = DRel, linetype = DRel),size = 1,stat = "summary", fun = "mean",)+
  geom_point(stat = "summary", fun = "mean", aes(shape = DRel))+
  facet_grid(.~ProbeSaliency)+labs(color  = "Distractor Relation", linetype = "Distractor Relation", shape = "Distractor Relation")+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("ProbeRT (in ms)")+xlab("Response Relation")+ggtitle("Interaction of Response Relation and \n Distractor Relation across Saliency")
plotDRRR

```

The DRel X RRel effects are significant for the salient trials. Below are the ANOVA results only with salient trials and the mean differences in the binding/retrieval effects.
There is a facilitation when the Distractor repeats (when the response repeats) of 39ms which is significant but the cost is not significant.

```{r}
SalientProbe<-subset(agg.out, subset=(ProbeSaliency=="salient"))
sal<-ezANOVA( data=SalientProbe,
                dv=RT_io,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
pander(sal, style = "rmarkdown", caption = "Only for salient trials")

meansal <- ezStats(data=SalientProbe,
        dv=RT_io,
        wid = participant,
        within = .(RRel),
        within_full = .(DRel, RRel),
        diff=.(DRel),
        reverse_diff = T)

pander(meansal, style = "rmarkdown", caption = "Mean differences between DC - DR for Response Relation only for salient trials")

#t.tests:
pander(t.test(RT_io ~ DRel, data =SalientProbe, subset =(RRel=="RR"), paired=TRUE, alternative="greater"),style = "rmarkdown", caption = "T-test results between DC and DR, only for Response Repetition trials" )

#facilitation sign

pander(t.test(RT_io ~ DRel, data =SalientProbe, subset =(RRel=="RC"), paired=TRUE, alternative="less"), style = "rmarkdown", caption = "T-test resuults between DC and DR, for Response Change trials (Costs)")

#cost ns
```

..and the effects for only the non salient trials are not significant.

```{r }

NonSalientProbe<-subset(agg.out, subset=(ProbeSaliency=="nonsalient"))
nonsal<-ezANOVA( data=NonSalientProbe,
                dv=RT_io,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
pander(nonsal, style = "rmarkdown", caption = "ANOVA for only non salient trials")

```


## 2. ANOVA: DRel, RRel, Probe saliency for binding trials with ERs

> The three way interaction is significant, $F = 4.91,p = 0.03$. The two way interaction between DRel X RRel is also significant, $F = 4.46, p = 0.03$


```{r}
anova2 <- ezANOVA(data = agg.err,
                  dv = err,
                  wid = .(participant),
                  within = .(DRel,RRel,ProbeSaliency),
                  detailed = TRUE)

pander(anova2, style = "rmarkdown", caption = "ANOVA (ERs): for binding trials DRel, RRel, Probe Saliency")
```

Similar to RTs, while looking at the salient trials alone, the DRel x RRel effect is significant $F = 7.5, p = 0.007$ 
Below are the ANOVA results along with the t-test results for each of the Response Relation to tease apart the facilitations and costs.
The facilitation is marginally significant but the cost is not significant. 

```{r}
SalientProbeER<-subset(agg.err, subset=(ProbeSaliency=="salient"))
salER<-ezANOVA( data=SalientProbeER,
                dv=err,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
pander(salER, style = "rmarkdown", caption = "Only for salient trials")

meansalER <- ezStats(data=SalientProbeER,
        dv=err,
        wid = participant,
        within = .(RRel),
        within_full = .(DRel, RRel),
        diff=.(DRel),
        reverse_diff = T)

pander(meansalER, style = "rmarkdown", caption = "Mean differences between DC - DR for Response Relation only for salient trials")

#t.tests:
pander(t.test(err ~ DRel, data =SalientProbeER, subset =(RRel=="RR"), paired=TRUE, alternative="greater"),style = "rmarkdown", caption = "T-test(ER) results between DC and DR, only for Response Repetition trials" )

#facilitation sign

pander(t.test(RT_io ~ DRel, data =SalientProbe, subset =(RRel=="RC"), paired=TRUE, alternative="less"), style = "rmarkdown", caption = "T-test resuults between DC and DR, for Response Change trials (Costs)")

#cost ns
```



```{r}
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#analysis at the trial level####

table(raw.data$DRel)
table(raw.data$RRel)
table(raw.data$ProbeSaliency)
table(raw.data$Validity)

#create numeric variables for Multilevel analysis

raw.data$drel<-ifelse(raw.data$DRel=="DR", 1, -1)
table(raw.data$drel, raw.data$DRel)
summary(raw.data$drel)

raw.data$probesal<-ifelse(raw.data$ProbeSaliency=="salient", 1, -1)
table(raw.data$probesal, raw.data$ProbeSaliency)
summary(raw.data$probesal)

raw.data$val<-ifelse(raw.data$Validity=="valid", 1, -1)
table(raw.data$val, raw.data$Validity)
summary(raw.data$val) #but already all invalid trials are removed

raw.data$rrel<-ifelse(raw.data$RRel=="RR", 1, 2)
table(raw.data$rrel, raw.data$RRel)


#centering within person for RREl
#previous_rm
means.rrel <- aggregate(data = raw.data, rrel ~ participant, mean)
names(means.rrel)[2]<-"rrel_mean"

raw.data<-merge (raw.data, means.rrel, by="participant")

raw.data$rrel_cwp <- raw.data$rrel-raw.data$rrel_mean
summary(raw.data$rrel_cwp)

#random slopes model, Probe RT
#RT
randomSlopes_m1<-lmer(RT_io~1+probesal*drel*rrel_cwp + (1+probesal*drel*rrel_cwp|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m1)
#threeway interaction sign

#errors

randomSlopes_m1_err<-lmer(err~1+probesal*drel*rrel_cwp + (1+probesal*drel*rrel_cwp|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m1_err)
#threeway interaction sign
#so far: MLM analyses correspond to analyses at the aggregated level!

#+++++++++++++++++++++++
#incorporate test trial validity to the model

#RT
randomSlopes_m2<-lmer(RT_io~1+probesal*drel*rrel_cwp*val + (1+probesal*drel*rrel_cwp*val|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")

summary(randomSlopes_m2)
#threeway interaction sign

#errors

randomSlopes_m2_err<-lmer(err~1+probesal*drel*rrel_cwp*val + (1+probesal*drel*rrel_cwp*val|participant), 
                          data=raw.data, 
                          REML=F,
                          na.action = "na.omit")

summary(randomSlopes_m2_err)


#test model fit
randomIntercept_m0<-lmer(RT_io~1 + (1|participant), 
                         data=raw.data, 
                         REML=F,
                         na.action = "na.omit")
summary(randomIntercept_m0)

randomIntercept_m0_err<-lmer(err~1 + (1|participant), 
                             data=raw.data, 
                             REML=F,
                             na.action = "na.omit")
summary(randomIntercept_m0_err)

#Model comparison
#Model 1 vs Model0

anova(randomIntercept_m0, randomSlopes_m1) #sign
anova(randomIntercept_m0_err, randomSlopes_m1_err) #sign

#Model 2 vs model 1
anova(randomSlopes_m1, randomSlopes_m2) #no sign model improvement
anova(randomSlopes_m1_err, randomSlopes_m2_err) #no sign model improvement

#check for confunds in the factorial design####
table(raw.data$DRel, raw.data$RRel )
round(table(raw.data$DRel, raw.data$RRel )/nrow(raw.data)*100, digits = 2)

table(raw.data$DRel, raw.data$RRel, raw.data$ProbeSaliency )
round(table(raw.data$DRel, raw.data$RRel, raw.data$ProbeSaliency )/nrow(raw.data)*100, digits = 1)

round(table(raw.data$DRel, raw.data$RRel, raw.data$ProbeSaliency, raw.data$Validity )/nrow(raw.data)*100, digits = 1)

table(raw.data$DRel, raw.data$RRel, raw.data$Validity, raw.data$ProbeSaliency) 

table(raw.data$DRel, raw.data$RRel, raw.data$Validity) 
round(table(raw.data$DRel, raw.data$RRel, raw.data$Validity) /nrow(raw.data)*100, digits = 1)


#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#Analyze Binding effect at the aggragted level, Probe performance as a function of ProbeSaliency, DRel, RREl####
#ANOVA

data<-read.csv2(file="Data/agg_out.csv")
data<-read.csv2(file="Data/agg_err.csv")

data<-OnlyVal_agg.out

data$DRel<-as.factor(data$DRel)
data$RRel<-as.factor(data$RRel)
data$participant<-as.factor(data$participant)
data$ProbeSaliency<-as.factor(data$ProbeSaliency)
#when validity is included: 16 cells, all participants have missing data


table(data$participant)


#RT####
ezout<-ezANOVA( data=data,
                dv=RT_io,
                wid = participant,
                within= .(DRel, RRel, ProbeSaliency),
                detailed=T)
anova_out(ezout)
#3way interaction is significant

#plot
#Grafik 
plot_RT<-ezPlot(data=data,
       dv=RT_io, 
       wid=participant, 
       within = .(DRel, RRel, ProbeSaliency), 
       x = RRel, 
       levels = list(RRel = list(new_order = c('RR', 'RC'))),
       split = DRel, 
       col = ProbeSaliency, 
       y_lab ='ProbeRT (ms)',
       do_bars =FALSE)+
  theme_bw()+ylim(500,600)

plotDRRR <- ggplot(data = data,aes(x = RRel, y = RT_io, color = DRel))+
  geom_line(aes(group = DRel, linetype = DRel),size = 1,stat = "summary", fun = "mean",)+
  geom_point(stat = "summary", fun = "mean", aes(shape = DRel))+
  facet_grid(.~ProbeSaliency)+labs(color  = "Distractor Relation", linetype = "Distractor Relation", shape = "Distractor Relation")+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("ProbeRT (in ms)")+xlab("Response Relation")+ggtitle("Interaction of Response Relation and \n Distractor Relation across Saliency")
plotDRRR


#graph shows standard binding for salient D, reversed pattern for nonsalient D
#follow up

SalientProbe<-subset(data, subset=(ProbeSaliency=="salient"))
ezout<-ezANOVA( data=SalientProbe,
                dv=RT_io,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
anova_out(ezout)
#DRelxRREl interaction sign

ezStats(data=SalientProbe,
        dv=RT_io,
        wid = participant,
        within = .(RRel),
        within_full = .(DRel, RRel),
        diff=.(DRel),
        reverse_diff = T)

#t.tests:
t<- t.test(RT_io ~ DRel, data =SalientProbe, subset =(RRel=="RR"), paired=TRUE, alternative="greater" )
t_out(t, d.corr=FALSE)
#facilitation sign

t<- t.test(RT_io ~ DRel, data =SalientProbe, subset =(RRel=="RC"), paired=TRUE, alternative="less" )
t_out(t, d.corr=FALSE)
#cost ns

NonSalientProbe<-subset(data, subset=(ProbeSaliency=="nonsalient"))
ezout<-ezANOVA( data=NonSalientProbe,
                dv=RT_io,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
anova_out(ezout)
#DRelxRrel ns

#Errors####
ezout<-ezANOVA( data=data,
                dv=err,
                wid = participant,
                within= .(DRel, RRel, ProbeSaliency),
                detailed=T)
anova_out(ezout)
#threeway iA sign

plotDRRR_err <- ggplot(data = data,aes(x = RRel, y = err, color = DRel))+
  geom_line(aes(group = DRel, linetype = DRel),size = 1,stat = "summary", fun = "mean",)+
  geom_point(stat = "summary", fun = "mean", aes(shape = DRel))+
  facet_grid(.~ProbeSaliency)+labs(color  = "Distractor Relation", linetype = "Distractor Relation", shape = "Distractor Relation")+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  coord_cartesian(ylim = c(0,0.15))+
  theme_classic()+ylab("ProbeErrorRate")+xlab("Response Relation")+ggtitle("Interaction of Response Relation and \n Distractor Relation across Saliency")
plotDRRR_err

#ggsave("Figures/ProbeSaliency x DRel x RRel_RT.png")
ggsave(filename = here("Figures","ProbeSalDRelRRel_err.png"),plotDRRR_err)

#plot
plot_err<-ezPlot(data=data,
       dv=err, 
       wid=participant, 
       within = .(DRel, RRel, ProbeSaliency), 
       x = RRel,
       levels = list(RRel = list(new_order = c('RR', 'RC'))),
       split = DRel, 
       y_lab ='Probe error rate',
       col = ProbeSaliency, 
       do_bars =FALSE)+
  theme_bw() 
print(plot_err)
ggsave("Figures/ProbeSaliency x DRel x RRel_errors.png")

#graph shows standard binding for salient D, reversed pattern for nonsalient D
#follow up

SalientProbe<-subset(data, subset=(ProbeSaliency=="salient"))
ezout<-ezANOVA( data=SalientProbe,
                dv=err,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
anova_out(ezout)
#DRelxRREl interaction sign

ezStats(data=SalientProbe,
        dv=err,
        wid = participant,
        within = .(RRel),
        within_full = .(DRel, RRel),
        diff=.(DRel),
        reverse_diff = T)

#t.tests:
t<- t.test(err ~ DRel, data =SalientProbe, subset =(RRel=="RR"), paired=TRUE, alternative="greater" )
t_out(t, d.corr=FALSE)
#facilitation marginal sign in one.taield test

t<- t.test(err ~ DRel, data =SalientProbe, subset =(RRel=="RC"), paired=TRUE, alternative="less" )
t_out(t, d.corr=FALSE)
#cost sign

NonSalientProbe<-subset(data, subset=(ProbeSaliency=="nonsalient"))
ezout<-ezANOVA( data=NonSalientProbe,
                dv=err,
                wid = participant,
                within= .(DRel, RRel),
                detailed=T)
anova_out(ezout)
#DRelxRrel ns
```